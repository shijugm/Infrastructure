Reference : https://towardsdatascience.com/a-journey-into-big-data-with-apache-spark-part-1-5dfcc2bccdd2

#######################################################################################
# this is the command to build the image once the image is built this is not needed
#######################################################################################


# need to check why the '.' is needed in the end of the command.

docker build  -t shiju/spark:2.3.0 .

#######################################################################################
# Run the command 
#######################################################################################

# create a network for master and slave
#########
 docker network create spark_network


# Start the spark master
########
 docker run --rm -it --name spark-master --hostname spark-master -p 7077:7077 -p 8081:8081  --network spark_network -v /home/shijugm/workarea/git/:/source  shiju/spark:2.3.0 /bin/bash

# Run this in the master
###
/spark/bin/spark-class org.apache.spark.deploy.master.Master --ip `hostname` --port 7077 --webui-port 8081


# Start the spark slave
########

 docker run --rm -it --name spark-worker --hostname spark-worker --network spark_network -v /home/shijugm/workarea/git/:/source shiju/spark:2.3.0 /bin/bash

# Run this on the slave to register
###
/spark/bin/spark-class org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://spark-master:7077

#REPEAT above slave commands for more slave nodes
# change the name each time


# create a node to submit the job. This container is not registered as a worker node
 docker run --rm -it --network spark_network --name spark-submit-driver -v  /home/shijugm/workarea/git/:/source -v  /home/shiju/workarea/git_repositories/datasets:/data shiju/spark:2.3.0  /bin/bash


# spark UI : localhost:8081/


# Refer the docker compose to finish all this in a script

